% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{fvextra}
\usepackage{unicode-math}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
\DefineVerbatimEnvironment{OutputCode}{Verbatim}{breaklines,commandchars=\\\{\}}
\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={HW 2},
  pdfauthor={Bryan Mui - UID 506021334 - 28 April 2025},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{HW 2}
\author{Bryan Mui - UID 506021334 - 28 April 2025}
\date{}

\begin{document}
\maketitle


Loaded packages: ggplot2, tidyverse (include = false for this chunk)

Reading the dataset:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"dataset{-}logistic{-}regression.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Rows: 10000 Columns: 101
-- Column specification --------------------------------------------------------
Delimiter: ","
dbl (101): y, X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14, X...

i Use `spec()` to retrieve the full column specification for this data.
i Specify the column types or set `show_col_types = FALSE` to quiet this message.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(data, }\AttributeTok{n =} \DecValTok{25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 25 x 101
       y      X1      X2     X3     X4     X5     X6      X7     X8      X9
   <dbl>   <dbl>   <dbl>  <dbl>  <dbl>  <dbl>  <dbl>   <dbl>  <dbl>   <dbl>
 1     1 -0.0895  0.450   1.71   0.657 -0.392  1.24   0.895   1.13  -0.0117
 2     1 -0.0943  0.281  -0.147 -0.701  0.400 -0.210  0.677  -0.440  0.458 
 3     0 -0.431  -0.445  -0.777 -0.832 -2.26  -1.62  -1.98   -1.67  -1.15  
 4     0  0.644   0.0817 -0.448  0.852 -1.02   0.671  0.299   0.145 -0.205 
 5     1 -0.919  -0.0241  0.807 -0.612 -0.498  0.350  1.12    0.242 -0.947 
 6     0 -1.89   -1.11   -0.210  0.161 -1.34  -2.04  -0.0135 -1.39  -1.31  
 7     0 -1.34   -0.804   0.322 -0.110  0.624 -0.329 -0.432  -0.191  0.171 
 8     1  0.329   0.468   0.719  0.588  1.71   1.39   0.603   0.650  0.161 
 9     0  0.332   1.42   -0.431  1.02   0.484  0.348  0.474   1.26  -0.479 
10     0 -0.311   0.0193  0.168 -0.346  0.626 -0.704 -0.290   0.680 -0.0453
# i 15 more rows
# i 91 more variables: X10 <dbl>, X11 <dbl>, X12 <dbl>, X13 <dbl>, X14 <dbl>,
#   X15 <dbl>, X16 <dbl>, X17 <dbl>, X18 <dbl>, X19 <dbl>, X20 <dbl>,
#   X21 <dbl>, X22 <dbl>, X23 <dbl>, X24 <dbl>, X25 <dbl>, X26 <dbl>,
#   X27 <dbl>, X28 <dbl>, X29 <dbl>, X30 <dbl>, X31 <dbl>, X32 <dbl>,
#   X33 <dbl>, X34 <dbl>, X35 <dbl>, X36 <dbl>, X37 <dbl>, X38 <dbl>,
#   X39 <dbl>, X40 <dbl>, X41 <dbl>, X42 <dbl>, X43 <dbl>, X44 <dbl>, ...
\end{verbatim}

Our data set has 10000 observations, 1 binary outcome variable y, and
100 predictor variables X1-X100

Separating into X matrix and y vector:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X }\OtherTok{\textless{}{-}}\NormalTok{ data }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{y)}
\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ data }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(y)}
\end{Highlighting}
\end{Shaded}

\section{Problem 1}\label{problem-1}

\subsection{\texorpdfstring{Part
(\(\symbf{\alpha}\))}{Part (\textbackslash symbf\{\textbackslash alpha\})}}\label{part-symbfalpha}

The optimization problem is to minimize the log-likelihood function.
From there we will get the objective function and gradient function

From the slides in class we have:

\[
\min_{\beta} (-\ell(\beta)) = \frac{1}{m} \sum_{i=1}^{m} f_i(\beta)
\]

and the equation for \(f_i(\beta)\):

\[
f_i(\beta) = -y_i(x_i^{\mathsf{T}}\beta) + log(1 + exp(x_i^{\mathsf{T}} \beta))
\] For the objective function, we get:

\[
f(\beta) = \frac{1}{m} \sum_{i=1}^{m} [-y_i(x_i^{\mathsf{T}}\beta) + log(1 + exp(x_i^{\mathsf{T}} \beta))]
\]

We can matricize the objective function to

\[
\boxed{f(\beta) = \frac{1}{m}[-y^{\mathsf{T}}(X\beta) + \mathbf{1}^{\mathsf{T}}log(1 + exp(X\beta))]}
\]

We also have the gradient function:

\[
\nabla f(x) = \frac{1}{m} \sum_{i=1}^m \nabla f_i(x)
\]

and

\[
\nabla_\beta f_i(\beta) = [\sigma(x_i^{\mathsf{T}} \beta) - y_i] \cdot x_i
\] where \(\sigma(z) = \frac{1}{1+exp(-z)}\) as the logistic sigmoid
function, therefore:

\[
\begin{aligned}
\nabla f(x) &= \frac{1}{m} \sum_{i=1}^m \nabla f_i(x), \; \nabla_\beta f_i(\beta) = [\sigma(x_i^{\mathsf{T}} \beta) - y_i] \cdot x_i \\
\nabla f(\beta) &= {\frac{1}{m} \sum_{i=1}^m [\sigma(x_i^{\mathsf{T}} \beta) - y_i] \cdot x_i}
\end{aligned}
\]

And we can also matricize this:

\[
\boxed{\nabla f(\beta) = \frac{1}{m} X^{\mathsf{T}}[\sigma(X\beta) - y], \quad \sigma(z) = \frac{1}{1+exp(-z)}}
\]

Therefore our gradient descent update step is(for constant step size):

\[
\boxed {\beta_{k+1} = \beta_k - \eta \nabla f(\beta_k)}
\]

\textbf{Implement the following algorithms to obtain estimates of the
regression coefficients \(\symbf{β}\):}

\subsubsection{(1) Gradient descent with backtracking line
search}\label{gradient-descent-with-backtracking-line-search}

Algorithm; Backtracking Line Search:

Params:

\begin{itemize}
\tightlist
\item
  Set \(η^0 > 0\)(usually a large value \textasciitilde1),
\item
  Set \(η_1 = η^0\)
\item
  Set \(ϵ ∈ (0,1), τ ∈ (0,1)\), where \(ϵ\) and \(τ\) are used to modify
  step size
\end{itemize}

Repeat:

\begin{itemize}
\tightlist
\item
  At iteration k, set \(η_k <- η_{k-1}\)

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \item
    Check whether the Armijo Condition holds: \[
    h(η_k) ≤ h(0) + ϵη_kh'(0)
    \]\\
    where \(h(η_k) = f(x_k) − η_k ∇f(x_k)\),\\
    and \(h(0) = f(x_k)\),\\
    and \(h'(0) = -||\nabla (x_k)||^2\)
  \item
  \end{enumerate}

  \begin{itemize}
  \tightlist
  \item
    If yes(condition holds), terminate and keep \(η_k\)
  \item
    If no, set \(η_k = τη_k\) and go to Step 1
  \end{itemize}
\end{itemize}

Stopping criteria: Stop if \(||x_k - x_{k+1}|| ≤ tol\) (change in
parameters is small)

\textbf{Implement BLS}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# logistic gradient descent w/ bls}
\NormalTok{log\_bls }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(X, y, }\AttributeTok{tol =} \FloatTok{1e{-}6}\NormalTok{, }\AttributeTok{max\_iter =} \DecValTok{10000}\NormalTok{, }\AttributeTok{epsilon =} \FloatTok{0.5}\NormalTok{, }\AttributeTok{tau =} \FloatTok{0.5}\NormalTok{) \{}
  \CommentTok{\# Initialize}
\NormalTok{  n }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(X)}
\NormalTok{  p }\OtherTok{\textless{}{-}} \FunctionTok{ncol}\NormalTok{(X)}
\NormalTok{  x }\OtherTok{\textless{}{-}} \FunctionTok{as.matrix}\NormalTok{(X)}
\NormalTok{  y }\OtherTok{\textless{}{-}} \FunctionTok{as.matrix}\NormalTok{(y)}
\NormalTok{  beta }\OtherTok{\textless{}{-}} \FunctionTok{as.matrix}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, p))}
\NormalTok{  obj\_values }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(max\_iter)}
\NormalTok{  eta\_values }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(max\_iter)  }\CommentTok{\# To store eta values used each iteration}
\NormalTok{  beta\_values }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{() }\CommentTok{\# To store beta values used each iteration}
\NormalTok{  eta\_bt }\OtherTok{\textless{}{-}} \DecValTok{1}  \CommentTok{\# Initial step size for backtracking}
  
  \CommentTok{\# Objective function: negative log{-}likelihood}
  \CommentTok{\# input: Beta vector, x matrix, y matrix}
  \CommentTok{\# output: scalar objective func value}
  \CommentTok{\# comments: We want to minimize this function for logit regression}
\NormalTok{  obj\_function }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(beta, x, y) \{}
\NormalTok{    m }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(x)}
\NormalTok{    z }\OtherTok{\textless{}{-}}\NormalTok{ x }\SpecialCharTok{\%*\%}\NormalTok{ beta}
\NormalTok{    (}\DecValTok{1} \SpecialCharTok{/}\NormalTok{ m) }\SpecialCharTok{*}\NormalTok{ (}\SpecialCharTok{{-}}\NormalTok{(}\FunctionTok{t}\NormalTok{(y) }\SpecialCharTok{\%*\%}\NormalTok{ z) }\SpecialCharTok{+} \FunctionTok{sum}\NormalTok{(}\FunctionTok{log}\NormalTok{(}\DecValTok{1} \SpecialCharTok{+} \FunctionTok{exp}\NormalTok{(z))))}
\NormalTok{  \}}
  
  \CommentTok{\# Gradient function}
  \CommentTok{\# input: Beta vector, x matrix, y matrix}
  \CommentTok{\# output: gradient vector in the dimension of nrow(Beta) x 1}
  \CommentTok{\# comments: We use this for gradient descent}
\NormalTok{  gradient }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(beta, x, y) \{}
\NormalTok{    m }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(x)                       }\CommentTok{\# define m}
\NormalTok{    sig }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(z) }\DecValTok{1} \SpecialCharTok{/}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+} \FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{z))  }\CommentTok{\# sigmoid function}
\NormalTok{    (}\DecValTok{1} \SpecialCharTok{/}\NormalTok{ m) }\SpecialCharTok{*}\NormalTok{ (}\FunctionTok{t}\NormalTok{(x) }\SpecialCharTok{\%*\%}\NormalTok{ (}\FunctionTok{sig}\NormalTok{(x }\SpecialCharTok{\%*\%}\NormalTok{ beta) }\SpecialCharTok{{-}}\NormalTok{ y))}
\NormalTok{  \}}

  \CommentTok{\# Algorithm:}
  \ControlFlowTok{for}\NormalTok{ (iter }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{max\_iter) \{}
\NormalTok{    grad }\OtherTok{\textless{}{-}} \FunctionTok{gradient}\NormalTok{(beta, x, y)}
    
    \CommentTok{\#cat("iter ", iter, "\textbackslash{}n")}
    
    \CommentTok{\# backtracking step}
\NormalTok{    current\_obj }\OtherTok{\textless{}{-}} \FunctionTok{obj\_function}\NormalTok{(beta, x, y)}
\NormalTok{    grad\_norm\_sq }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(grad}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
    
\NormalTok{    beta\_new }\OtherTok{\textless{}{-}}\NormalTok{ beta }\SpecialCharTok{{-}}\NormalTok{ eta\_bt }\SpecialCharTok{*}\NormalTok{ grad}
    
    \ControlFlowTok{while}\NormalTok{ (}\FunctionTok{obj\_function}\NormalTok{(beta\_new, x, y) }\SpecialCharTok{\textgreater{}}\NormalTok{ current\_obj }\SpecialCharTok{{-}}\NormalTok{ epsilon }\SpecialCharTok{*}\NormalTok{ eta\_bt }\SpecialCharTok{*}\NormalTok{ grad\_norm\_sq) \{}
\NormalTok{      eta\_bt }\OtherTok{\textless{}{-}}\NormalTok{ tau }\SpecialCharTok{*}\NormalTok{ eta\_bt}
\NormalTok{      beta\_new }\OtherTok{\textless{}{-}}\NormalTok{ beta }\SpecialCharTok{{-}}\NormalTok{ eta\_bt }\SpecialCharTok{*}\NormalTok{ grad}
\NormalTok{    \}}
    
    \CommentTok{\# save values to the matrix}
\NormalTok{    eta\_values[iter] }\OtherTok{\textless{}{-}}\NormalTok{ eta\_bt}
\NormalTok{    obj\_values[iter] }\OtherTok{\textless{}{-}} \FunctionTok{obj\_function}\NormalTok{(beta\_new, x, y)}
\NormalTok{    beta\_values[[iter]] }\OtherTok{\textless{}{-}}\NormalTok{ beta\_new}
    
    \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{sum}\NormalTok{((beta\_new }\SpecialCharTok{{-}}\NormalTok{ beta)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)) }\SpecialCharTok{\textless{}}\NormalTok{ tol) \{}
      \CommentTok{\# set the vector ranges and break}
\NormalTok{      beta }\OtherTok{\textless{}{-}}\NormalTok{ beta\_new}
\NormalTok{      obj\_values }\OtherTok{\textless{}{-}}\NormalTok{ obj\_values[}\DecValTok{1}\SpecialCharTok{:}\NormalTok{iter]}
\NormalTok{      eta\_values }\OtherTok{\textless{}{-}}\NormalTok{ eta\_values[}\DecValTok{1}\SpecialCharTok{:}\NormalTok{iter]}
\NormalTok{      beta\_values }\OtherTok{\textless{}{-}}\NormalTok{ beta\_values[}\DecValTok{1}\SpecialCharTok{:}\NormalTok{iter]}
      \ControlFlowTok{break}
\NormalTok{    \}}
    
\NormalTok{    beta }\OtherTok{\textless{}{-}}\NormalTok{ beta\_new}
\NormalTok{  \}}
  
  \FunctionTok{return}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{beta =}\NormalTok{ beta, }\AttributeTok{obj\_values =}\NormalTok{ obj\_values, }\AttributeTok{eta\_values =}\NormalTok{ eta\_values, }\AttributeTok{beta\_values =}\NormalTok{ beta\_values))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\textbf{TESTING: BLS}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{log\_reg\_bls }\OtherTok{\textless{}{-}} \FunctionTok{log\_bls}\NormalTok{(X, y, }\AttributeTok{tol=}\FloatTok{1e{-}6}\NormalTok{, }\AttributeTok{max\_iter=}\DecValTok{10000}\NormalTok{, }\AttributeTok{epsilon=}\FloatTok{0.5}\NormalTok{, }\AttributeTok{tau=}\FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cat}\NormalTok{(}\StringTok{"betas }\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
betas 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(log\_reg\_bls}\SpecialCharTok{$}\NormalTok{beta)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                 y
X1   -0.1418188273
X2   -0.0601340162
X3    0.1588169528
X4    0.1328223189
X5   -0.0480437781
X6    0.0992481092
X7    0.1189707785
X8    0.1165560855
X9    0.0121222291
X10   0.0002641372
X11   0.0440526577
X12  -0.1793886158
X13  -0.0107332284
X14  -0.1230510680
X15   0.0724799230
X16   0.0571868940
X17   0.1299458439
X18   0.1249113906
X19  -0.0018170795
X20   0.1248825007
X21  -0.0107845610
X22  -0.1431801553
X23  -0.1094846603
X24   0.0576435159
X25  -0.1190174922
X26   0.0164879978
X27  -0.0977482724
X28   0.1544632196
X29  -0.0276524076
X30   0.0164226883
X31  -0.0589010945
X32   0.0205242099
X33   0.1352153619
X34  -0.0301792708
X35  -0.0097106467
X36   0.0631274232
X37   0.1972595891
X38   0.0932479560
X39   0.1242393813
X40   0.1466042152
X41   0.1112967707
X42  -0.1226544766
X43  -0.0374866338
X44  -0.0155583465
X45  -0.0103256878
X46  -0.1807311531
X47   0.0122916067
X48   0.0309436582
X49   0.0257891274
X50   0.1230837280
X51  -0.0237134869
X52  -0.0136672407
X53   0.0802510780
X54   0.1695795679
X55   0.1711403640
X56  -0.0447703054
X57  -0.0407325139
X58  -0.0768578382
X59   0.0786448045
X60  -0.1192193182
X61  -0.0080431756
X62   0.0701535429
X63   0.0295238798
X64  -0.1090225592
X65   0.0633967271
X66  -0.1450871355
X67   0.1404424947
X68   0.0649021774
X69  -0.1595801011
X70   0.1128079446
X71   0.1888668197
X72   0.0920649207
X73  -0.0647758044
X74  -0.0684344716
X75   0.2306707321
X76  -0.1312078759
X77   0.0301767178
X78  -0.0742090881
X79   0.0695790861
X80  -0.0273839196
X81   0.0183730389
X82   0.0555339156
X83  -0.0196159895
X84  -0.0119020076
X85   0.0981161430
X86   0.1724354285
X87   0.0832570899
X88  -0.0070115810
X89   0.0720539875
X90   0.0779093972
X91   0.0026928031
X92  -0.1223692130
X93   0.0073627318
X94  -0.0996425700
X95  -0.0485788118
X96   0.0338587696
X97   0.1496954257
X98   0.1702285222
X99   0.0197714549
X100  0.0070161693
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cat}\NormalTok{(}\StringTok{"The function converged after"}\NormalTok{, }\FunctionTok{length}\NormalTok{(log\_reg\_bls}\SpecialCharTok{$}\NormalTok{obj\_values), }\StringTok{" iterations }\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
The function converged after 1909  iterations 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cat}\NormalTok{(}\StringTok{"Eta Vals: }\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Eta Vals: 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(log\_reg\_bls}\SpecialCharTok{$}\NormalTok{eta\_values[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{50}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625
[11] 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625
[21] 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625
[31] 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625
[41] 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cat}\NormalTok{(}\StringTok{"Objective Function vals }\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Objective Function vals 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(log\_reg\_bls}\SpecialCharTok{$}\NormalTok{obj\_values[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{50}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 0.5642463 0.5491551 0.5446388 0.5427888 0.5418291 0.5412092 0.5407301
 [8] 0.5403132 0.5399257 0.5395537 0.5391908 0.5388343 0.5384829 0.5381361
[15] 0.5377934 0.5374547 0.5371200 0.5367892 0.5364622 0.5361389 0.5358194
[22] 0.5355035 0.5351913 0.5348826 0.5345775 0.5342759 0.5339777 0.5336830
[29] 0.5333916 0.5331036 0.5328188 0.5325373 0.5322591 0.5319840 0.5317120
[36] 0.5314432 0.5311774 0.5309146 0.5306549 0.5303981 0.5301442 0.5298932
[43] 0.5296451 0.5293997 0.5291572 0.5289174 0.5286804 0.5284460 0.5282142
[50] 0.5279851
\end{verbatim}

\subsubsection{(2) Gradient descent with backtracking line search and
Nesterov
momentum}\label{gradient-descent-with-backtracking-line-search-and-nesterov-momentum}

Nesterov is simply BLS with a special way to select the momentum
\(\xi\),

We set \(\xi\) to:

\[
\frac{k-1}{k+2}
\]

where k is the iteration index

Algorithm(Nesterov Momentum with BLS)

Params:

\begin{itemize}
\tightlist
\item
  Set \(η^0 > 0\)(usually a large value \textasciitilde1),
\item
  Set \(η_1 = η^0\)
\item
  Set \(ϵ ∈ (0,1), τ ∈ (0,1)\), where \(ϵ\) and \(τ\) are used to modify
  step size
\end{itemize}

Repeat:

\begin{itemize}
\tightlist
\item
  At iteration k, set \(η_k <- η_{k-1}\), update with
\end{itemize}

\[
\boxed{x_{k+1} = y_k - \eta_k \nabla (f(y_k)), \quad y_k = x_k + \xi(x_k - x_{k-1}), \quad \xi = \frac{k-1}{k+2}}
\]

\begin{itemize}
\tightlist
\item
  Check the next setting of \(\eta\):

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Check whether the Armijo Condition holds:
  \end{enumerate}

  \[
  h(η_k) ≤ h(0) + ϵη_kh'(0)
  \]\\
  where \(h(η_k) = f(x_k) − η_k ∇f(x_k)\),\\
  and \(h(0) = f(x_k)\),\\
  and \(h'(0) = -||\nabla (x_k)||^2\)

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{1}
  \tightlist
  \item
  \end{enumerate}

  \begin{itemize}
  \tightlist
  \item
    If yes(condition holds), terminate and keep \(η_k\)
  \item
    If no, set \(η_k = τη_k\) and go to Step 1
  \end{itemize}
\end{itemize}

Stopping criteria: Stop if \(||x_k - x_{k+1}|| ≤ tol\) (change in
parameters is small)

\subsubsection{(3) Gradient descent with AMSGrad-ADAM
momentum}\label{gradient-descent-with-amsgrad-adam-momentum}

(no backtracking line search, since AMSGrad-ADAM adjusts step sizes per
parameter using momentum and adaptive scaling)

\subsubsection{(4) Stochastic gradient descent with a fixed schedule of
decreasing step
sizes}\label{stochastic-gradient-descent-with-a-fixed-schedule-of-decreasing-step-sizes}

\subsubsection{(5) Stochastic gradient descent with AMSGrad-ADAM-W
momentum}\label{stochastic-gradient-descent-with-amsgrad-adam-w-momentum}

\subsection{Part (a)}\label{part-a}

\subsection{Part (b)}\label{part-b}




\end{document}
