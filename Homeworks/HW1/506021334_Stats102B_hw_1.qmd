---
title: "HW 1"
author: "Bryan Mui - UID 506021334 - 14 April 2025"
format: 
  pdf:
    keep-tex: true
    include-in-header: 
       text: |
         \usepackage{fvextra}
         \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
         \DefineVerbatimEnvironment{OutputCode}{Verbatim}{breaklines,commandchars=\\\{\}}
---

Loaded packages: ggplot2, tidyverse (include = false for this chunk)
```{r options}
#| include: false
options(max.print = 50)
library(ggplot2)
library(tidyverse)
```


# Problem 1 

## Part a 

Find the theoretical min for the function: 
$$
f(x) = x^4 + 2x^2 + 1
$$

Solution: find f'(x) and f''(x), set f'(x) to 0 and solve, and f''(x) needs to be > 0 to be a min

Step 1: find f'(x) and f''(x)
\begin{align}
  f(x) &= x^4 + 2x^2 + 1 \\ 
 f'(x) &= 4x^3 + 4x  \\
f''(x) &= 12x^2 + 4 \\
\end {align}

Step 2: set f'(x) to 0 and solve

\begin{align}
f'(x) &= 4x^3 + 4x  \\
    0 &= 4x^3 + 4x \\
    0 &= 4x(x^2 + 4)
\end{align}


We get $$x = 0$$ and $$0 = x^2 +4$$ which has no real solution

Step 3: check that f''(x) needs to be > 0 to be a min

Our critical point is x = 0,  

\begin{align}
f''(0)  &= 12(0)^2 + 4 \\
        &= 4
\end{align}

Since f'(x) = 0 at 0 and f''(x) > 0 at that point, **we have a min at x = 0, and plugging into f(0) we get the minimum point**
\begin{center} (0, 1) \end{center}  


## Part b 

### 0) 

Use the gradient descent algorithm with **constant step size** and with **back-tracking line search** to calculate $x_{min}$

**Constant step size descent is implemented as follows:**

1. Select a random starting point $x_0$    
2. While stopping criteria < tolerance, do:  

  * Select $η_k$(as a constant)  
  * Calculate $x_{(k+1)} = x_k - η_k * ∇(f(x_k))$  
  * Calculate the value of stopping criterion  
  
Stopping criteria: Stop if $∣|∇(f(x_k)||_2 ≤ ϵ$ 
  

```{r grad_descent_constant_step}
# Gradient descent algorithm that uses backtracking to minimize an objective function

gradient_descent_constant_step <- function(tol = 1e-6, max_iter = 10000, step_size = 0.01) {
  # Step 1: Initialize and select a random stopping point
  # Initialize
  set.seed(777) # example seeding 
  last_iter <- 0 # the last iteration ran
  eta <- step_size # step size that is decided manually 
  max_iter <- max_iter # max iterations before terminating if mininum isn't found
  tolerance <- tol # tolerance for the stoppign criteria 
  obj_values <- numeric(max_iter) # Stores the value of f(x)
  eta_values <- numeric(max_iter)  # To store eta values used each iteration
  eta_values[1] <- step_size
  betas <- numeric(max_iter) # Stores the value of x guesses
  x0 <- runif(1, min=-10, max=10) # our first guess is somewhere between -10-10
  
  # Set the objective function to the function to be minimized 
  # Objective function: f(x)
  obj_function <- function(x) {
    return(x^4 + 2*(x^2) + 1) 
  }
  
  # Gradient function: d/dx of f(x)
  gradient <- function(x) {
    return(4*x^3 + 4*x)
  }
  
  # Append the first guess to the obj_values and betas vector
  betas[1] <- x0
  obj_values[1] <- obj_function(x0)
  
  # Step 2: While stopping criteria < tolerance, do:
  for (iter in 1:max_iter) { # the iteration goes n = 1, 2, 3, 4, but the arrays of our output starts at iter = 0 and guess x0
    # Select eta(step size), which is constant
    # There's nothing to do for this step
    
    # Calculate the next guess of x_k+1, calculate f(x_k+1), set eta(x_k+1)
    betas[iter + 1] <- betas[iter] - (eta * gradient(betas[iter]))
    obj_values[iter + 1] <- obj_function(betas[iter + 1])
    eta_values[iter + 1] <- eta
    
    # Calculate the value of the stopping criterion
    stop_criteria <- abs(gradient(betas[iter + 1]))
    
    # If stopping criteria less than tolerance, break
    if(is.na(stop_criteria) || stop_criteria <= tolerance) { 
      last_iter <- iter + 1
      break 
    }
    
    # if we never set last iter, then we hit the max number of iterations and need to set
    if(last_iter == 0) { last_iter <- max_iter }
    
    # end algorithm
  }
  
  return(list(betas = betas, obj_values = obj_values, eta_values = eta_values, last_iter = last_iter)) # in this case, beta(predictors) are the x values, obj_values are f(x), eta is the step size, last iter is the value in the vector of the final iteration before stopping
}
```

Running the gradient descent algorithm with fixed step size:

```{r minimizing_constant_step}
minimize_constant_step <- gradient_descent_constant_step(tol = 1e-6, max_iter = 10000, step_size = 0.03)
print(minimize_constant_step)

cat("The functions stopped after", minimize_constant_step$last_iter - 1, "iterations \n")
cat("The function's point of minimization is", "(", minimize_constant_step$betas[minimize_constant_step$last_iter], "," , minimize_constant_step$obj_values[minimize_constant_step$last_iter], ") \n")
```

**Backtracking Line Search is implemented as follows:**  

1. Select a random starting point $x_0$    
2. While stopping criteria < tolerance, do:  

  * Select $η_k$ using backtracking line search
  * Calculate $x_{(k+1)} = x_k - η_k * ∇(f(x_k))$  
  * Calculate the value of stopping criterion  
  
Backtracking Line Search:  

  * Set $η^0 > 0$(usually a large value), $ϵ ∈ (0,1)$ and $τ ∈ (0,1)$
  * Set $η_1 = η^0$ 
  * At iteration k, set $η_k <- η_{k-1}$
    1. Check whether the Armijo Condition holds: 
    $$
    h(η_k) ≤ h(0) + ϵη_kh'(0)
    $$  
      where $h(η_k) = f(x_k) − η_k ∇f(x_k)$
    2. 
      + If yes(condition holds), terminate and keep $η_k$
      + If no, set $η_k = τη_k$ and go to Step 1

Stopping criteria: Stop if $∣|∇(f(x_k)||_2 ≤ ϵ$ 

Other note: Since we need h'(0) for the Armijo condition calculation, that is given by:  
$$
h'(0) = -[∇f(x_k)]^\top ∇f(x_k)
$$
Since we are minimizing x, we have a one dimensional beta, we can simplify to  
$$
h'(0) = -||∇f(x_k)||^2
$$

To summarize, backtracking line search chooses the step size by ensuring the Armijo condition always holds. If the Armijo condition doesn't hold, we are probably overshooting, hence the step size gets updated iteratively 

```{r backtracking_line_search_grad_descent}
gradient_descent_backtracking <- function(tol = 1e-6, max_iter = 10000, epsilon = 0.5, tau = 0.5, init_step_size = 1) {
  # Step 1: Initialize and select a random stopping point
  # Initialize
  set.seed(777) # example seeding 
  last_iter <- 0 # the last iteration ran
  max_iter <- max_iter # max iterations before terminating if minimum isn't found
  tolerance <- tol # tolerance for the stopping criteria 
  epsilon <- epsilon # Epsilon used in the step size criteria calculation
  tau <- tau # tau used in the step size criteria calculation
  obj_values <- numeric(max_iter) # Stores the value of f(x)
  eta_values <- numeric(max_iter)  # To store eta values used each iteration
  eta_values[1] <- init_step_size
  betas <- numeric(max_iter) # Stores the value of x guesses
  x0 <- runif(1, min=-10, max=10) # our first guess is somewhere between -10 to 10
  eta <- init_step_size # our initial step size
  
  # Set the objective function to the function to be minimized 
  # Objective function: f(x)
  obj_function <- function(x) {
    return(x^4 + 2*(x^2) + 1) 
  }
  
  # Gradient function: d/dx of f(x)
  gradient <- function(x) {
    return(4*x^3 + 4*x)
  }
  
  # Armijo condition function
  # returns TRUE or FALSE whether the condition is satisfied or not
  armijo_stepsize <- function(beta, eta, grad, f, epsilon, tau, max_iter) {
    subiter <- 1 # set a hard limit of iterations
    # calc armijo
    beta_new <- beta - (eta)*grad(beta)
    armijo <- f(beta_new) > (f(beta) - epsilon*eta*sum(grad(beta)^2))
    while (armijo && (iter <= max_iter)) {
      #update eta
      eta <- tau * eta
      
      #recalculate armijo
      beta_new <- beta - (eta)*grad(beta)
      armijo <- f(beta_new) > (f(beta) - epsilon*eta*sum(grad(beta)^2))
      
      subiter <- subiter + 1
    }
    return(eta)
  }
  
  # Append the first guess to the obj_values and betas vector
  betas[1] <- x0
  obj_values[1] <- obj_function(x0)
  
  # Step 2: While stopping criteria < tolerance, do:
  for (iter in 1:max_iter) { # the iteration goes n = 1, 2, 3, 4, but the arrays of our output starts at iter = 0 and guess x0
    beta <- betas[iter]
    
    # use BLS to calculate eta
    eta <- armijo_stepsize(beta = beta, eta = eta, grad = gradient, f = obj_function, epsilon = epsilon, tau = tau, max_iter = max_iter)
    eta_values[iter + 1] <- eta
    
    # Calculate the next guess of x_k+1
    beta_new <- beta - (eta * gradient(beta))
    betas[iter + 1] <- beta_new
    
    # calculate f(x_k+1), to keep track obj values
    obj_values[iter + 1] <- obj_function(beta_new)
    
    # Calculate the value of the stopping criterion
    stop_criteria <- abs(gradient(beta_new))
    
    # If stopping criteria less than tolerance, break
    if(is.na(stop_criteria) || stop_criteria <= tolerance) { 
      last_iter <- iter + 1
      break 
    }
    
    # if we never set last iter, then we hit the max number of iterations and need to set
    if(last_iter == 0) { last_iter <- max_iter }
    
    # end algorithm
  }
  
  return(list(betas = betas, obj_values = obj_values, eta_values = eta_values, last_iter = last_iter)) # in this case, beta(predictors) are the x values, obj_values are f(x), eta is the step size, last iter is the value in the vector of the final iteration before stopping
}
```

Running the gradient descent algorithm with backtracking:

```{r minimizing_backtracking}
minimize_backtrack <- gradient_descent_backtracking(tol = 1e-6, max_iter = 10000, epsilon = 0.5, tau = 0.8, init_step_size = 1)
print(minimize_backtrack)

cat("The functions stopped after", minimize_backtrack$last_iter - 1, "iterations \n")
cat("The function's point of minimization is", "(", minimize_backtrack$betas[minimize_backtrack$last_iter], "," , minimize_backtrack$obj_values[minimize_backtrack$last_iter], ") \n")
```

### 1) For the constant step size version of gradient descent, discuss how you selected the step size used in your code

Theoretical Analysis proves that for functions with a unique global minimum, the step size should be within 0 to 1/L to converge to the unique global minimum, where L is the Lipchitz constant, given by:  

$$
||∇f(x) - ∇f(y)||_2 \le L||x - y||_2
$$
Since this cannot be calculated in practice, usually a small step size of 0.01 is what to begin with. From there, manually fine tuning to try 0.02 and 0.03 is a good idea to see if there's any better iterations. Starting from a big step size is usually unsafe do the algorithm overshooting and diverging instead of converging. Ultimately, the step size of 0.02 seemed best to reduce the number of iterations.

### 2) For both versions of the gradient descent algorithm, plot the value of $f(x_k)$ as a function of k the number of iterations

```{r}
# constant step size
iterations <- 1:minimize_constant_step$last_iter
obj_values <- (minimize_constant_step$obj_values)[iterations]
f_k_constant <- cbind(obj_values, iterations)

iterations <- 1:minimize_backtrack$last_iter
obj_values <- (minimize_backtrack$obj_values)[iterations]
f_k_backtrack <- cbind(obj_values, iterations)

ggplot(f_k_constant, aes(x=iterations, y=obj_values)) + 
  geom_point() + 
  geom_line() + 
  ggtitle("Gradient Descent Convergence, Constant Step Size") + 
  xlab("Iteration") + ylab("Objective Function Value")
ggplot(f_k_backtrack, aes(x=iterations, y=obj_values)) + 
  geom_point() + 
  geom_line() + 
  ggtitle("Gradient Descent Convergence, Backtracking Line Search") + 
  xlab("Iteration") + ylab("Objective Function Value")
```


### 3) For the the gradient descent method with backtracking line search, plot the step size $η_k$ selected at step k as a function of k. Comment on the result

```{r}
iterations <- 1:minimize_backtrack$last_iter
eta_values <- minimize_backtrack$eta_values[iterations]
eta_backtrack <- cbind(eta_values, iterations)

ggplot(eta_backtrack, aes(x=iterations, y=eta_values)) + 
  geom_point(color = "blue") + 
  geom_line(color = "blue") + 
  ggtitle("Gradient Descent Eta Values, BLS") + 
  xlab("Iteration") + ylab("Eta Value")
```

We can see that the step size was initially 0.02, but at the very first few iterations the Armijo condition immediately reduced the step size to a very small number < 0.005 in order to prevent overshooting. This condition held for the rest of the iterations until the algorithm converged eventually, after around 443 iterations. Compared to the constant step size gradient descent, the step size was much smaller for all the iterations, meaning that it converged with > 300 more iterations than the constant step size gradient descent. Although using a large step size like 0.02 would be much faster, it seems like the step sizes were chosen to be a safer bound so that the algorithm would not overshoot

# Problem 2

**To understand the sensitivity of the gradient descent algorithm and its variants to the “shape” of the function, the two data sets provided (dataset1.csv, dataset2.csv) will be used**

They contain 100 observations for a response $y$ and 20 predictors $x_j, j = 1, · · · , 20$

## Part a 

Using the gradient descent code provided (both in R and Python) obtain the estimates of the regression coefficient, using both a constant step size and backtracking line search.

Read in the data and the gradient descent function:

```{r}
dataset1 <- read_csv("dataset1.csv")
dataset2 <- read_csv("dataset2.csv")

# gradient descent given in class
gradient_descent_class <- function(X, y, eta = NULL, tol = 1e-6, max_iter = 10000, backtracking = TRUE, epsilon = 0.5, tau = 0.8) {
  # Initialize
  n <- nrow(X)
  p <- ncol(X)
  beta <- rep(0, p)
  obj_values <- numeric(max_iter)
  eta_values <- numeric(max_iter)  # To store eta values used each iteration
  eta_bt <- 1  # Initial step size for backtracking
  
  # Objective function: Mean Squared Error (MSE)
  obj_function <- function(beta) {
    sum((X %*% beta - y)^2) / (2 * n)
  }
  
  # Gradient function
  gradient <- function(beta) {
    t(X) %*% (X %*% beta - y) / n
  }
  
  for (iter in 1:max_iter) {
    grad <- gradient(beta)
    
    if (backtracking) {
      if (iter == 1) eta_bt <- 1  # Reset only in the first iteration
      beta_new <- beta - eta_bt * grad
      
      while (obj_function(beta_new) > obj_function(beta) - epsilon * eta_bt * sum(grad^2)) {
        eta_bt <- tau * eta_bt
        beta_new <- beta - eta_bt * grad
      }
      eta_used <- eta_bt
    } else {
      if (is.null(eta)) stop("When backtracking is FALSE, a fixed eta must be provided.")
      beta_new <- beta - eta * grad
      eta_used <- eta
    }
    
    eta_values[iter] <- eta_used
    
    obj_values[iter] <- obj_function(beta_new)
    
    if (sqrt(sum((beta_new - beta)^2)) < tol) {
      obj_values <- obj_values[1:iter]
      eta_values <- eta_values[1:iter]
      break
    }
    
    beta <- beta_new
  }
  
  return(list(beta = beta, obj_values = obj_values, eta_values = eta_values))
}
```


```{r regression_constant_step}
#| fig-width: 10
X_dataset_1 <- dataset1 %>%
  select(-Y) %>%
  as.matrix()
y_dataset_1 <- dataset1 %>%
  select(Y) %>%
  as.matrix()
X_dataset_2 <- dataset2 %>%
  select(-Y) %>%
  as.matrix()
y_dataset_2 <- dataset2 %>%
  select(Y) %>%
  as.matrix()

reg_const_dataset_1 <- gradient_descent_class(X_dataset_1, y_dataset_1, backtracking = FALSE, eta = 0.01)
reg_const_dataset_2 <- gradient_descent_class(X_dataset_2, y_dataset_2, backtracking = FALSE, eta = 0.01)


```


```{r regression_bls}
#| fig-width: 10
reg_bls_data1 <- gradient_descent_class(X_dataset_1, y_dataset_1, eta = NULL, tol = 1e-6, max_iter = 10000, backtracking = TRUE, epsilon = 0.5, tau = 0.8)
reg_bls_data2 <- gradient_descent_class(X_dataset_1, y_dataset_1, eta = NULL, tol = 1e-6, max_iter = 10000, backtracking = TRUE, epsilon = 0.5, tau = 0.8)


```


### 1) Discuss how you selected the constant step size. Also, discuss which convergence criterion you used and the tolerance parameter used 

```{r}

```


### 2) Compare the results with those obtained from the lm command in R or from the class LinearRegression from the sklearn.linear model in Python. 

Specifically, calculate $∥ \hat{β_{GD}} − \hatβ∥_2$, where $\hat{β_{GD}}$ is the estimate of the regression coefficient obtained from the gradient descent algorithm (both with constant step size and backtracking line search) and $\hatβ$ obtained from the least squares solution implemented in R or Python

```{r}

```


### 3) Plot the value of the objective function as a function of the number of iterations required

```{r 2-a-3}
#| fig-width: 10
par(mfrow=c(2,2))

plot(reg_const_dataset_1$obj_values, type = "o", col = "blue", pch = 16, cex = 0.5,
     xlab = "Iteration", ylab = "Objective Function Value",
     main = "Gradient Descent Convergence, Const Step, dataset1")
plot(reg_const_dataset_2$obj_values, type = "o", col = "blue", pch = 16, cex = 0.5,
     xlab = "Iteration", ylab = "Objective Function Value",
     main = "Gradient Descent Convergence, Const Step, dataset2")
plot(reg_bls_data1$obj_values, type = "o", col = "blue", pch = 16, cex = 0.5,
     xlab = "Iteration", ylab = "Objective Function Value",
     main = "Gradient Descent Convergence, BLS, dataset1")
plot(reg_bls_data2$obj_values, type = "o", col = "blue", pch = 16, cex = 0.5,
     xlab = "Iteration", ylab = "Objective Function Value, dataset2",
     main = "Gradient Descent Convergence, BLS, dataset2")
```
## Part b

**Implement the Polyak and Nesterov momentum methods and obtain the estimates of the regression coefficients, using both a constant step size and backtracking line search**
