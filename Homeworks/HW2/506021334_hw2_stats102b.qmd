---
title: "HW 2"
author: "Bryan Mui - UID 506021334 - 28 April 2025"
format: 
  pdf:
    latex-engine: pdflatex
    keep-tex: true
    include-in-header: 
       text: |
         \usepackage{fvextra}
         \usepackage{unicode-math}
         \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
         \DefineVerbatimEnvironment{OutputCode}{Verbatim}{breaklines,commandchars=\\\{\}}
---

Loaded packages: ggplot2, tidyverse (include = false for this chunk)
```{r options}
#| include: false
library(tidyverse)
```

Reading the dataset:
```{r read}
data <- read_csv("dataset-logistic-regression.csv")
head(data, n = 25)
```

Our data set has 10000 observations, 1 binary outcome variable y, and 100 predictor variables X1-X100

Separating into X matrix and y vector:

```{r}
X <- data %>%
  select(-y)
y <- data %>%
  select(y)
```


# Problem 1

## Part ($\symbf{\alpha}$)

The optimization problem is to minimize the log-likelihood function. From there we will get the objective function and gradient function

From the slides in class we have:

$$
\min_{\beta} (-\ell(\beta)) = \frac{1}{m} \sum_{i=1}^{m} f_i(\beta)
$$

and the equation for $f_i(\beta)$:

$$
f_i(\beta) = -y_i(x_i^{\mathsf{T}}\beta) + log(1 + exp(x_i^{\mathsf{T}} \beta))
$$
For the objective function, we get:

$$
f(\beta) = \frac{1}{m} \sum_{i=1}^{m} [-y_i(x_i^{\mathsf{T}}\beta) + log(1 + exp(x_i^{\mathsf{T}} \beta))]
$$


We can matricize the objective function to

$$
\boxed{f(\beta) = \frac{1}{m}[-y^{\mathsf{T}}(X\beta) + \mathbf{1}^{\mathsf{T}}log(1 + exp(X\beta))]}
$$

We also have the gradient function:

$$
\nabla f(x) = \frac{1}{m} \sum_{i=1}^m \nabla f_i(x)
$$

and

$$
\nabla_\beta f_i(\beta) = [\sigma(x_i^{\mathsf{T}} \beta) - y_i] \cdot x_i
$$
where $\sigma(z) = \frac{1}{1+exp(-z)}$ as the logistic sigmoid function, therefore:

$$
\begin{aligned}
\nabla f(x) &= \frac{1}{m} \sum_{i=1}^m \nabla f_i(x), \; \nabla_\beta f_i(\beta) = [\sigma(x_i^{\mathsf{T}} \beta) - y_i] \cdot x_i \\
\nabla f(\beta) &= {\frac{1}{m} \sum_{i=1}^m [\sigma(x_i^{\mathsf{T}} \beta) - y_i] \cdot x_i}
\end{aligned}
$$

And we can also matricize this:

$$
\boxed{\nabla f(\beta) = \frac{1}{m} X^{\mathsf{T}}[\sigma(X\beta) - y], \quad \sigma(z) = \frac{1}{1+exp(-z)}}
$$

Therefore our gradient descent update step is(for constant step size):

$$
\boxed {\beta_{k+1} = \beta_k - \eta \nabla f(\beta_k)}
$$

**Implement the following algorithms to obtain estimates of the regression coefficients $\symbf{β}$:**

### (1) Gradient descent with backtracking line search

Algorithm; Backtracking Line Search:  

Params:

  * Set $η^0 > 0$(usually a large value ~1), 
  * Set $η_1 = η^0$ 
  * Set $ϵ ∈ (0,1), τ ∈ (0,1)$, where $ϵ$ and $τ$ are used to modify step size
  
Repeat:

  * At iteration k, set $η_k <- η_{k-1}$
    1. Check whether the Armijo Condition holds: 
    $$
    h(η_k) ≤ h(0) + ϵη_kh'(0)
    $$  
      where $h(η_k) = f(x_k) − η_k ∇f(x_k)$,  
      and $h(0) = f(x_k)$,  
      and $h'(0) = -||\nabla (x_k)||^2$  
      
    2. 
      + If yes(condition holds), terminate and keep $η_k$
      + If no, set $η_k = τη_k$ and go to Step 1

Stopping criteria: Stop if $||x_k - x_{k+1}|| ≤ tol$ (change in parameters is small)

**Implement BLS**
```{r grad-bls}
# logistic gradient descent w/ bls
log_bls <- function(X, y, tol = 1e-6, max_iter = 10000, epsilon = 0.5, tau = 0.5) {
  # Initialize
  n <- nrow(X)
  p <- ncol(X)
  x <- as.matrix(X)
  y <- as.matrix(y)
  beta <- as.matrix(rep(0, p))
  obj_values <- numeric(max_iter)
  eta_values <- numeric(max_iter)  # To store eta values used each iteration
  beta_values <- list() # To store beta values used each iteration
  eta_bt <- 1  # Initial step size for backtracking
  
  # Objective function: negative log-likelihood
  # input: Beta vector, x matrix, y matrix
  # output: scalar objective func value
  # comments: We want to minimize this function for logit regression
  obj_function <- function(beta, x, y) {
    m <- nrow(x)
    z <- x %*% beta
    (1 / m) * (-(t(y) %*% z) + sum(log(1 + exp(z))))
  }
  
  # Gradient function
  # input: Beta vector, x matrix, y matrix
  # output: gradient vector in the dimension of nrow(Beta) x 1
  # comments: We use this for gradient descent
  gradient <- function(beta, x, y) {
    m <- nrow(x)                       # define m
    sig <- function(z) 1 / (1 + exp(-z))  # sigmoid function
    (1 / m) * (t(x) %*% (sig(x %*% beta) - y))
  }

  # Algorithm:
  for (iter in 1:max_iter) {
    grad <- gradient(beta, x, y)
    
    #cat("iter ", iter, "\n")
    
    # backtracking step
    current_obj <- obj_function(beta, x, y)
    grad_norm_sq <- sum(grad^2)
    
    beta_new <- beta - eta_bt * grad
    
    while (obj_function(beta_new, x, y) > current_obj - epsilon * eta_bt * grad_norm_sq) {
      eta_bt <- tau * eta_bt
      beta_new <- beta - eta_bt * grad
    }
    
    # save values to the matrix
    eta_values[iter] <- eta_bt
    obj_values[iter] <- obj_function(beta_new, x, y)
    beta_values[[iter]] <- beta_new
    
    if (sqrt(sum((beta_new - beta)^2)) < tol) {
      # set the vector ranges and break
      beta <- beta_new
      obj_values <- obj_values[1:iter]
      eta_values <- eta_values[1:iter]
      beta_values <- beta_values[1:iter]
      break
    }
    
    beta <- beta_new
  }
  
  return(list(beta = beta, obj_values = obj_values, eta_values = eta_values, beta_values = beta_values))
}
```

**TESTING: BLS**
```{r testing-bls}
log_reg_bls <- log_bls(X, y, tol=1e-6, max_iter=10000, epsilon=0.5, tau=0.5)
```

```{r}
cat("betas \n")
print(log_reg_bls$beta)
cat("The function converged after", length(log_reg_bls$obj_values), " iterations \n")
cat("Eta Vals: \n")
print(log_reg_bls$eta_values[1:50])
cat("Objective Function vals \n")
print(log_reg_bls$obj_values[1:50])
```


### (2) Gradient descent with backtracking line search and Nesterov momentum

Nesterov is simply BLS with a special way to select the momentum $\xi$,  

We set $\xi$ to:

$$
\frac{k-1}{k+2}
$$

where k is the iteration index

Algorithm(Nesterov Momentum with BLS)

Params:

  * Set $η^0 > 0$(usually a large value ~1), 
  * Set $η_1 = η^0$ 
  * Set $ϵ ∈ (0,1), τ ∈ (0,1)$, where $ϵ$ and $τ$ are used to modify step size
  
Repeat:

  * At iteration k, set $η_k <- η_{k-1}$, update with 
  
$$
\boxed{x_{k+1} = y_k - \eta_k \nabla (f(y_k)), \quad y_k = x_k + \xi(x_k - x_{k-1}), \quad \xi = \frac{k-1}{k+2}}
$$
  
  * Check the next setting of $\eta$:
    1. Check whether the Armijo Condition holds: 
  
    $$
    h(η_k) ≤ h(0) + ϵη_kh'(0)
    $$  
    where $h(η_k) = f(x_k) − η_k ∇f(x_k)$,  
    and $h(0) = f(x_k)$,  
    and $h'(0) = -||\nabla (x_k)||^2$  
    2. 
      + If yes(condition holds), terminate and keep $η_k$
      + If no, set $η_k = τη_k$ and go to Step 1

Stopping criteria: Stop if $||x_k - x_{k+1}|| ≤ tol$ (change in parameters is small)


### (3) Gradient descent with AMSGrad-ADAM momentum

(no backtracking line search, since AMSGrad-ADAM adjusts step sizes per parameter using momentum and adaptive scaling)

### (4) Stochastic gradient descent with a fixed schedule of decreasing step sizes

### (5) Stochastic gradient descent with AMSGrad-ADAM-W momentum 

(no backtracking line search, since AMSGrad-ADAM adjusts step sizes per parameter using momentum and adaptive scaling)

## Part (a) Hyperparameter Discussion

## Part (b) Metrics